{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87604ac3-0a8a-404f-9a66-c339c1b4fbe5",
   "metadata": {},
   "source": [
    "### To work on problems of imbalanced dataset, you need to install following library:\n",
    "### pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5346eab-d0c2-471e-b11a-4cfbd91357fb",
   "metadata": {},
   "source": [
    "What are imbalanced dataset??\n",
    "\n",
    "When in dependent variable, the number of records for one class are too huge as compared to the records present in other class. For example, in credit card fraud detection, no fraud records are in lakhs and fraud records are in 100's. This type of data is considered as imbalanced dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66904e6e-b531-4be7-a0d4-099e12a23343",
   "metadata": {},
   "source": [
    "Different ways to handle imbalanced dataset.\n",
    "\n",
    "1. Under Sampling\n",
    "2. Over Sampling\n",
    "3. SMOTETomek\n",
    "4. Ensemble Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba8d853-3db3-4ba8-b584-d613686e4590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We should be using the above mentioned methods/ should take care of imbalanced dataset when we are working on model creation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febaea74-d7c3-4b16-8865-a97be7476423",
   "metadata": {},
   "source": [
    "# 1. Undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b118f5-d547-4c2f-a040-dfbce8b289d9",
   "metadata": {},
   "source": [
    "To undersatnd undersampling concept, lets take the following example\n",
    "suppose class 0 has 10,000 records and class 1 has 100 records.\n",
    "\n",
    "Now here, by using undersampling, we would try to reduce the points of maximum labels. So, in above example, we would try to reduce the count of records of class 0 as it has huge number of records.\n",
    "\n",
    "## Usually you should use undersampling when you have very small dataset.\n",
    "\n",
    "How it works??\n",
    "\n",
    "After applying the function on train data with parameter (x) (for example x=0.8), records - from the class which had huge number of records, would get reduced to a number such that other class would have x percantage of records.\n",
    "\n",
    "simple example: \n",
    "\n",
    "if initially class 0 : 10,000 class 1 : 100\n",
    "After applying function with parameter 0.8, class 0 would have x*80/100=100  x=125\n",
    "\n",
    "so class 0 would have 125 records now.\n",
    "\n",
    "Once, undersampling is done, try applying model on new undersampled data and check the accuracy.\n",
    "\n",
    "If you perform this, the model would not give better accuracy as we have reduced the data size. \n",
    "## Do not use undersampling as it reduces the size of data (important info too) resulting in reducing the accuracy of model (check precision , recall etc., not just accuracy)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27fcf5d-3636-486c-ad80-9ae0be8c807f",
   "metadata": {},
   "source": [
    "# 2. Over Sampling\n",
    "\n",
    "In over sampling, we try to increase the number records present in class which had few records. So, if we pass parameter=0.5, it means, new record number in class (with few records) would be 50% of records present in class (with huge number of records).\n",
    "\n",
    "Oversampling works better on imbalanced datasets as it increases the points in data which eventually increases the accuracy, precision, recall of model.\n",
    "\n",
    "In oversampling, same points would be created/ copied again to create new data in a class which has fewer points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8eab505-be70-4424-923c-6bac1137582e",
   "metadata": {},
   "source": [
    "# Interview question regarding handling the imbalanced dataset\n",
    "\n",
    "If the dataset is small, we would definitely go with undersampling, but we would be focisng on all performnce matrix like recall, precison, f1_score. Apart from that, based on domain knowledge, we whould focus on reducing false positives or false negatives.\n",
    "Based on that, we would select ROC score i.e the probability value which  would be 0.6 or 0.7 etc. Finally we would perform SMOT techniques, oversampling techniques but would always revolve around the performance matrix. If this methods are not working we would go with ensemble techniques like random forest, XGBoost where we would provide class weight parameters and then probably it would perform well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a552b654-07f4-4193-9d5e-4289a83956b0",
   "metadata": {},
   "source": [
    "# 3. SMOTETomek\n",
    "\n",
    "SMOTETomek would create new points for the class whose points are lesser. In over sampling, the extra data which was getting created was the exact similar copy of point which were present in a class. But in SMOTE, the extra data its creating is not the duplication of the points present for that class, but those new points/data are the neighbours of the original data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914bd997-4df9-435a-ab68-78bc4ecf3c09",
   "metadata": {},
   "source": [
    "# 4. Ensemble Techniques\n",
    "\n",
    "Here we use EasyEnsembleClassfier. This classifier is an ensemble of AdaBoost learners trained on different balanced bootstrap samples. The balancing is achieved by random under-sampling. Check the practical example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdce4f5-7b69-46f4-9992-d61154d15f7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
